# Question Difficulty Estimation from Text with Natural Language Processing Techniques
Abstract
In recent years, significant research efforts have been devoted to the task of Question Difficulty Estimation from Text (QDET) using Natural Language Processing (NLP) techniques. This research aims to address the limitations of traditional question calibration approaches. However, prior investigations have primarily focused on individual domains without conducting quantitative comparisons between different models from diverse educational domains. This work aims to bridge this gap by quantitatively analyzing various approaches proposed in previous research and comparing their performance on a publicly available real-world dataset containing Science MCQs. Our findings indicate that hybrid models tend to outperform single-feature-based models, linguistic features excel in reading comprehension questions, while frequency-based features (TF-IDF) yield better results in domain knowledge assessment.
